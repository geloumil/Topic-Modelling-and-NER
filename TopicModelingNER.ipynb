{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"5\">Excersise 3 in Natural Language Processing</font>\n",
    "<br>\n",
    "<font color=\"#5642C2\" size=\"4\">Topic Modeling</font>\n",
    "<br>\n",
    "<font color=\"#5642C2\" size=\"3\">Author:</font><font color=\"#ADADAD\" size=\"3\">Angeliki Mylonaki</font>\n",
    "<br>\n",
    "<font color=\"#5642C2\" size=\"3\">Github:</font> https://github.com/geloumil/Topic-Modelling-and-NER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "def getData(regex):\n",
    "\n",
    "    file_list=[]\n",
    "    trainFiles = glob.glob(os.path.join(\".\", regex)) #make list of paths\n",
    "\n",
    "    for fd in trainFiles:\n",
    "        with codecs.open(fd, encoding='utf-8', errors='ignore') as fp:\n",
    "            file_list.append(fp.read().encode(\"utf-8\"))\n",
    "            \n",
    "    return file_list\n",
    "\n",
    "documents=getData(\"./nipstxt/nips*/*\")\n",
    "print type(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"3\">Mining Documents</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import corpus\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def mineDocs(documents):\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    minedList=[]\n",
    "    \n",
    "    stopWords = corpus.stopwords.words(\"english\")\n",
    "    documents=[s.translate(None, string.punctuation) for s in documents]\n",
    "    documents=[s.translate(None, \"\\x7f\") for s in documents]   \n",
    "    for doc in documents:\n",
    "         \n",
    "        #splitting document into sentences\n",
    "        sentences = sent_tokenize(doc)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            #removing digits\n",
    "            sentence=sentence.translate(None, string.digits)\n",
    "            \n",
    "            #converting to lowercase\n",
    "            sentence=sentence.lower()\n",
    "            \n",
    "            #removing stopwords\n",
    "            sentence=' '.join([word for word in sentence.split() if word not in stopWords])\n",
    "            \n",
    "            #removing single letter words\n",
    "            sentence=' '.join([word for word in sentence.split() if len(word) >1 ])\n",
    "            \n",
    "            #getting words of phrase\n",
    "            words=word_tokenize(sentence)\n",
    "            \n",
    "            #stemming and lemmatizing\n",
    "            words=[porter_stemmer.stem(word) for word in words]\n",
    "            words=[wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "                      \n",
    "            minedList.append(sentence)\n",
    "            \n",
    "    return minedList\n",
    "\n",
    "\n",
    "\n",
    "mdocs=mineDocs(documents)\n",
    "mdocs_tokenized=[doc.split() for doc in mdocs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"3\">Vectorizing,TF-IDF </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=\"english\", binary=\"true\")\n",
    "m_docs_vector = count_vect.fit_transform(mdocs)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False).fit(m_docs_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"3\">Creating Document-term Matrix</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(mdocs_tokenized)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in mdocs_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"3\">LDA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For numberOfTopics= 10  and a=  auto\n",
      "[(0, u'0.006*\"set\" + 0.006*\"network\" + 0.005*\"learning\" + 0.005*\"neural\" + 0.004*\"networks\"'), (1, u'0.005*\"function\" + 0.005*\"one\" + 0.005*\"time\" + 0.004*\"neural\" + 0.004*\"model\"'), (2, u'0.008*\"learning\" + 0.006*\"data\" + 0.006*\"model\" + 0.005*\"network\" + 0.005*\"using\"'), (3, u'0.006*\"model\" + 0.005*\"neural\" + 0.005*\"network\" + 0.004*\"figure\" + 0.004*\"learning\"'), (4, u'0.008*\"learning\" + 0.007*\"network\" + 0.007*\"model\" + 0.006*\"figure\" + 0.006*\"neural\"'), (5, u'0.007*\"learning\" + 0.006*\"figure\" + 0.005*\"network\" + 0.004*\"function\" + 0.004*\"model\"'), (6, u'0.008*\"network\" + 0.006*\"learning\" + 0.006*\"model\" + 0.005*\"function\" + 0.005*\"neural\"'), (7, u'0.006*\"learning\" + 0.006*\"network\" + 0.006*\"function\" + 0.005*\"model\" + 0.005*\"neural\"'), (8, u'0.008*\"network\" + 0.006*\"input\" + 0.006*\"learning\" + 0.005*\"networks\" + 0.005*\"model\"'), (9, u'0.010*\"network\" + 0.007*\"neural\" + 0.006*\"model\" + 0.006*\"using\" + 0.005*\"learning\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 10  and a=  asymmetric\n",
      "[(0, u'0.008*\"network\" + 0.007*\"neural\" + 0.006*\"input\" + 0.006*\"learning\" + 0.006*\"model\"'), (1, u'0.007*\"function\" + 0.006*\"neural\" + 0.006*\"learning\" + 0.006*\"network\" + 0.005*\"one\"'), (2, u'0.007*\"learning\" + 0.006*\"time\" + 0.005*\"neural\" + 0.005*\"model\" + 0.004*\"network\"'), (3, u'0.008*\"network\" + 0.007*\"neural\" + 0.007*\"learning\" + 0.005*\"input\" + 0.005*\"model\"'), (4, u'0.007*\"learning\" + 0.007*\"network\" + 0.006*\"training\" + 0.005*\"model\" + 0.005*\"input\"'), (5, u'0.007*\"model\" + 0.006*\"using\" + 0.005*\"learning\" + 0.005*\"data\" + 0.005*\"input\"'), (6, u'0.007*\"network\" + 0.005*\"function\" + 0.005*\"neural\" + 0.004*\"learning\" + 0.004*\"networks\"'), (7, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"set\" + 0.006*\"figure\" + 0.005*\"neural\"'), (8, u'0.005*\"model\" + 0.005*\"network\" + 0.005*\"learning\" + 0.004*\"set\" + 0.004*\"time\"'), (9, u'0.007*\"model\" + 0.007*\"network\" + 0.007*\"data\" + 0.006*\"learning\" + 0.005*\"one\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 10  and a=  symmetric\n",
      "[(0, u'0.007*\"network\" + 0.006*\"model\" + 0.005*\"time\" + 0.005*\"networks\" + 0.005*\"neural\"'), (1, u'0.008*\"learning\" + 0.006*\"network\" + 0.006*\"input\" + 0.005*\"networks\" + 0.005*\"function\"'), (2, u'0.010*\"network\" + 0.009*\"learning\" + 0.007*\"data\" + 0.005*\"figure\" + 0.005*\"neural\"'), (3, u'0.006*\"network\" + 0.006*\"neural\" + 0.006*\"learning\" + 0.005*\"set\" + 0.005*\"networks\"'), (4, u'0.008*\"learning\" + 0.006*\"network\" + 0.005*\"networks\" + 0.004*\"figure\" + 0.004*\"model\"'), (5, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"neural\" + 0.006*\"time\" + 0.006*\"input\"'), (6, u'0.006*\"network\" + 0.006*\"data\" + 0.006*\"model\" + 0.006*\"learning\" + 0.005*\"training\"'), (7, u'0.006*\"network\" + 0.006*\"neural\" + 0.006*\"learning\" + 0.006*\"input\" + 0.005*\"model\"'), (8, u'0.010*\"model\" + 0.006*\"neural\" + 0.005*\"one\" + 0.004*\"learning\" + 0.004*\"data\"'), (9, u'0.008*\"network\" + 0.007*\"model\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.005*\"function\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 50  and a=  auto\n",
      "[(0, u'0.006*\"learning\" + 0.005*\"function\" + 0.005*\"one\" + 0.005*\"network\" + 0.005*\"model\"'), (1, u'0.009*\"learning\" + 0.007*\"function\" + 0.006*\"network\" + 0.005*\"training\" + 0.005*\"model\"'), (2, u'0.007*\"learning\" + 0.006*\"network\" + 0.004*\"units\" + 0.004*\"output\" + 0.004*\"model\"'), (3, u'0.006*\"learning\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"neural\" + 0.005*\"algorithm\"'), (4, u'0.009*\"learning\" + 0.007*\"network\" + 0.005*\"algorithm\" + 0.005*\"data\" + 0.004*\"figure\"'), (5, u'0.006*\"training\" + 0.006*\"set\" + 0.006*\"data\" + 0.006*\"learning\" + 0.005*\"network\"'), (6, u'0.010*\"model\" + 0.007*\"using\" + 0.006*\"data\" + 0.006*\"network\" + 0.005*\"input\"'), (7, u'0.009*\"learning\" + 0.007*\"network\" + 0.006*\"function\" + 0.005*\"two\" + 0.005*\"set\"'), (8, u'0.008*\"network\" + 0.007*\"input\" + 0.006*\"neural\" + 0.006*\"figure\" + 0.005*\"networks\"'), (9, u'0.006*\"learning\" + 0.006*\"network\" + 0.006*\"model\" + 0.005*\"neural\" + 0.005*\"input\"'), (10, u'0.012*\"neural\" + 0.010*\"network\" + 0.007*\"networks\" + 0.005*\"input\" + 0.005*\"function\"'), (11, u'0.010*\"network\" + 0.007*\"neural\" + 0.005*\"data\" + 0.005*\"input\" + 0.005*\"function\"'), (12, u'0.011*\"network\" + 0.006*\"learning\" + 0.006*\"neural\" + 0.006*\"input\" + 0.005*\"training\"'), (13, u'0.005*\"network\" + 0.005*\"function\" + 0.005*\"input\" + 0.005*\"using\" + 0.005*\"neural\"'), (14, u'0.006*\"model\" + 0.005*\"data\" + 0.005*\"learning\" + 0.004*\"network\" + 0.004*\"using\"'), (15, u'0.008*\"model\" + 0.007*\"network\" + 0.006*\"function\" + 0.005*\"input\" + 0.004*\"neural\"'), (16, u'0.007*\"network\" + 0.005*\"learning\" + 0.005*\"networks\" + 0.005*\"data\" + 0.005*\"input\"'), (17, u'0.008*\"learning\" + 0.008*\"training\" + 0.005*\"data\" + 0.004*\"function\" + 0.004*\"network\"'), (18, u'0.008*\"learning\" + 0.007*\"time\" + 0.005*\"networks\" + 0.004*\"function\" + 0.004*\"model\"'), (19, u'0.005*\"model\" + 0.005*\"time\" + 0.005*\"function\" + 0.005*\"network\" + 0.004*\"input\"'), (20, u'0.008*\"model\" + 0.007*\"learning\" + 0.005*\"network\" + 0.005*\"figure\" + 0.005*\"time\"'), (21, u'0.008*\"network\" + 0.006*\"data\" + 0.006*\"model\" + 0.005*\"figure\" + 0.005*\"one\"'), (22, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"neural\" + 0.005*\"networks\" + 0.005*\"data\"'), (23, u'0.007*\"model\" + 0.006*\"network\" + 0.006*\"set\" + 0.005*\"neural\" + 0.005*\"learning\"'), (24, u'0.007*\"network\" + 0.005*\"set\" + 0.005*\"learning\" + 0.004*\"training\" + 0.004*\"data\"'), (25, u'0.006*\"model\" + 0.006*\"learning\" + 0.005*\"neural\" + 0.005*\"training\" + 0.005*\"used\"'), (26, u'0.006*\"model\" + 0.006*\"network\" + 0.005*\"neural\" + 0.005*\"learning\" + 0.005*\"using\"'), (27, u'0.008*\"network\" + 0.006*\"learning\" + 0.005*\"input\" + 0.004*\"system\" + 0.004*\"neural\"'), (28, u'0.009*\"model\" + 0.006*\"network\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.005*\"learning\"'), (29, u'0.006*\"learning\" + 0.006*\"model\" + 0.006*\"network\" + 0.006*\"networks\" + 0.005*\"neural\"'), (30, u'0.014*\"learning\" + 0.008*\"network\" + 0.006*\"data\" + 0.006*\"one\" + 0.005*\"neural\"'), (31, u'0.007*\"set\" + 0.007*\"network\" + 0.006*\"neural\" + 0.005*\"model\" + 0.005*\"learning\"'), (32, u'0.007*\"model\" + 0.006*\"learning\" + 0.005*\"network\" + 0.005*\"neural\" + 0.005*\"figure\"'), (33, u'0.006*\"learning\" + 0.006*\"neural\" + 0.005*\"two\" + 0.005*\"network\" + 0.005*\"networks\"'), (34, u'0.008*\"network\" + 0.006*\"model\" + 0.006*\"figure\" + 0.005*\"learning\" + 0.005*\"input\"'), (35, u'0.007*\"learning\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"time\" + 0.005*\"two\"'), (36, u'0.010*\"network\" + 0.007*\"networks\" + 0.006*\"model\" + 0.006*\"neural\" + 0.005*\"learning\"'), (37, u'0.009*\"model\" + 0.005*\"data\" + 0.005*\"figure\" + 0.005*\"function\" + 0.005*\"time\"'), (38, u'0.009*\"learning\" + 0.006*\"network\" + 0.005*\"one\" + 0.005*\"set\" + 0.004*\"function\"'), (39, u'0.006*\"learning\" + 0.006*\"data\" + 0.006*\"figure\" + 0.005*\"networks\" + 0.005*\"model\"'), (40, u'0.010*\"network\" + 0.006*\"input\" + 0.005*\"learning\" + 0.005*\"model\" + 0.005*\"one\"'), (41, u'0.007*\"network\" + 0.006*\"model\" + 0.006*\"neural\" + 0.006*\"learning\" + 0.006*\"function\"'), (42, u'0.009*\"network\" + 0.006*\"one\" + 0.006*\"neural\" + 0.005*\"set\" + 0.005*\"input\"'), (43, u'0.008*\"network\" + 0.008*\"learning\" + 0.008*\"neural\" + 0.006*\"model\" + 0.006*\"networks\"'), (44, u'0.006*\"model\" + 0.006*\"neural\" + 0.005*\"figure\" + 0.005*\"network\" + 0.005*\"training\"'), (45, u'0.008*\"learning\" + 0.006*\"neural\" + 0.006*\"network\" + 0.006*\"data\" + 0.006*\"input\"'), (46, u'0.008*\"model\" + 0.005*\"figure\" + 0.005*\"data\" + 0.005*\"network\" + 0.005*\"one\"'), (47, u'0.008*\"learning\" + 0.006*\"network\" + 0.006*\"neural\" + 0.005*\"input\" + 0.005*\"model\"'), (48, u'0.006*\"network\" + 0.005*\"input\" + 0.005*\"figure\" + 0.005*\"model\" + 0.004*\"learning\"'), (49, u'0.005*\"function\" + 0.005*\"one\" + 0.005*\"system\" + 0.004*\"input\" + 0.004*\"network\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 50  and a=  asymmetric\n",
      "[(0, u'0.012*\"network\" + 0.007*\"learning\" + 0.006*\"neural\" + 0.006*\"training\" + 0.006*\"networks\"'), (1, u'0.007*\"learning\" + 0.007*\"network\" + 0.006*\"function\" + 0.006*\"neural\" + 0.005*\"time\"'), (2, u'0.006*\"neural\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"learning\" + 0.005*\"training\"'), (3, u'0.007*\"network\" + 0.005*\"one\" + 0.005*\"neural\" + 0.005*\"set\" + 0.005*\"learning\"'), (4, u'0.009*\"network\" + 0.006*\"neural\" + 0.005*\"networks\" + 0.005*\"model\" + 0.005*\"input\"'), (5, u'0.008*\"network\" + 0.006*\"learning\" + 0.006*\"model\" + 0.006*\"training\" + 0.005*\"networks\"'), (6, u'0.007*\"network\" + 0.007*\"model\" + 0.006*\"training\" + 0.005*\"learning\" + 0.005*\"one\"'), (7, u'0.007*\"model\" + 0.005*\"information\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.004*\"time\"'), (8, u'0.006*\"network\" + 0.006*\"neural\" + 0.006*\"model\" + 0.005*\"data\" + 0.005*\"learning\"'), (9, u'0.007*\"learning\" + 0.006*\"one\" + 0.006*\"network\" + 0.006*\"neural\" + 0.005*\"system\"'), (10, u'0.007*\"network\" + 0.007*\"model\" + 0.006*\"neural\" + 0.006*\"input\" + 0.005*\"figure\"'), (11, u'0.007*\"network\" + 0.007*\"neural\" + 0.007*\"input\" + 0.005*\"one\" + 0.005*\"function\"'), (12, u'0.007*\"neural\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"figure\" + 0.005*\"input\"'), (13, u'0.008*\"network\" + 0.006*\"model\" + 0.006*\"learning\" + 0.005*\"figure\" + 0.005*\"time\"'), (14, u'0.006*\"network\" + 0.006*\"input\" + 0.006*\"function\" + 0.005*\"data\" + 0.005*\"neural\"'), (15, u'0.005*\"network\" + 0.005*\"data\" + 0.004*\"time\" + 0.004*\"figure\" + 0.004*\"two\"'), (16, u'0.011*\"learning\" + 0.006*\"network\" + 0.005*\"set\" + 0.005*\"neural\" + 0.005*\"data\"'), (17, u'0.007*\"learning\" + 0.006*\"neural\" + 0.005*\"network\" + 0.005*\"data\" + 0.004*\"networks\"'), (18, u'0.008*\"learning\" + 0.006*\"neural\" + 0.006*\"network\" + 0.005*\"function\" + 0.005*\"one\"'), (19, u'0.008*\"learning\" + 0.006*\"network\" + 0.005*\"algorithm\" + 0.005*\"figure\" + 0.005*\"networks\"'), (20, u'0.009*\"model\" + 0.005*\"figure\" + 0.005*\"learning\" + 0.005*\"time\" + 0.005*\"input\"'), (21, u'0.006*\"model\" + 0.005*\"network\" + 0.005*\"input\" + 0.005*\"figure\" + 0.004*\"learning\"'), (22, u'0.008*\"learning\" + 0.008*\"network\" + 0.007*\"networks\" + 0.006*\"model\" + 0.005*\"input\"'), (23, u'0.007*\"data\" + 0.006*\"learning\" + 0.006*\"model\" + 0.006*\"network\" + 0.005*\"neural\"'), (24, u'0.009*\"learning\" + 0.007*\"network\" + 0.005*\"one\" + 0.005*\"model\" + 0.005*\"neural\"'), (25, u'0.007*\"network\" + 0.007*\"model\" + 0.006*\"learning\" + 0.005*\"one\" + 0.004*\"networks\"'), (26, u'0.008*\"neural\" + 0.007*\"model\" + 0.006*\"input\" + 0.005*\"time\" + 0.004*\"learning\"'), (27, u'0.007*\"data\" + 0.007*\"model\" + 0.006*\"network\" + 0.006*\"set\" + 0.005*\"learning\"'), (28, u'0.007*\"data\" + 0.007*\"model\" + 0.005*\"neural\" + 0.005*\"using\" + 0.005*\"learning\"'), (29, u'0.009*\"learning\" + 0.007*\"network\" + 0.006*\"figure\" + 0.006*\"neural\" + 0.006*\"model\"'), (30, u'0.006*\"model\" + 0.005*\"learning\" + 0.005*\"function\" + 0.004*\"two\" + 0.004*\"input\"'), (31, u'0.008*\"learning\" + 0.005*\"function\" + 0.005*\"data\" + 0.005*\"input\" + 0.004*\"neural\"'), (32, u'0.008*\"model\" + 0.005*\"network\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.005*\"one\"'), (33, u'0.007*\"network\" + 0.006*\"learning\" + 0.005*\"algorithm\" + 0.005*\"function\" + 0.005*\"model\"'), (34, u'0.009*\"model\" + 0.005*\"learning\" + 0.005*\"set\" + 0.004*\"data\" + 0.004*\"used\"'), (35, u'0.007*\"learning\" + 0.005*\"function\" + 0.005*\"model\" + 0.004*\"set\" + 0.004*\"one\"'), (36, u'0.007*\"network\" + 0.005*\"figure\" + 0.005*\"data\" + 0.005*\"learning\" + 0.005*\"using\"'), (37, u'0.009*\"learning\" + 0.006*\"training\" + 0.006*\"function\" + 0.006*\"set\" + 0.006*\"network\"'), (38, u'0.010*\"learning\" + 0.009*\"network\" + 0.007*\"function\" + 0.007*\"model\" + 0.007*\"data\"'), (39, u'0.008*\"network\" + 0.006*\"model\" + 0.006*\"time\" + 0.005*\"neural\" + 0.005*\"learning\"'), (40, u'0.007*\"network\" + 0.007*\"model\" + 0.006*\"data\" + 0.006*\"training\" + 0.005*\"set\"'), (41, u'0.006*\"state\" + 0.006*\"network\" + 0.005*\"learning\" + 0.005*\"model\" + 0.005*\"neural\"'), (42, u'0.006*\"input\" + 0.005*\"network\" + 0.005*\"one\" + 0.004*\"algorithm\" + 0.004*\"learning\"'), (43, u'0.007*\"neural\" + 0.006*\"learning\" + 0.006*\"network\" + 0.005*\"model\" + 0.005*\"algorithm\"'), (44, u'0.010*\"network\" + 0.007*\"training\" + 0.006*\"neural\" + 0.006*\"one\" + 0.005*\"networks\"'), (45, u'0.006*\"network\" + 0.005*\"input\" + 0.005*\"data\" + 0.004*\"set\" + 0.004*\"neural\"'), (46, u'0.007*\"neural\" + 0.006*\"network\" + 0.005*\"networks\" + 0.005*\"model\" + 0.004*\"learning\"'), (47, u'0.007*\"input\" + 0.006*\"network\" + 0.006*\"model\" + 0.005*\"figure\" + 0.004*\"neural\"'), (48, u'0.009*\"network\" + 0.006*\"neural\" + 0.006*\"training\" + 0.005*\"input\" + 0.005*\"learning\"'), (49, u'0.007*\"learning\" + 0.007*\"network\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.005*\"networks\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 50  and a=  symmetric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.007*\"learning\" + 0.005*\"model\" + 0.005*\"neural\" + 0.004*\"network\" + 0.004*\"two\"'), (1, u'0.006*\"learning\" + 0.005*\"function\" + 0.005*\"network\" + 0.005*\"model\" + 0.005*\"used\"'), (2, u'0.008*\"model\" + 0.006*\"figure\" + 0.006*\"learning\" + 0.005*\"network\" + 0.004*\"algorithm\"'), (3, u'0.007*\"network\" + 0.006*\"function\" + 0.006*\"model\" + 0.005*\"learning\" + 0.005*\"output\"'), (4, u'0.009*\"network\" + 0.007*\"learning\" + 0.006*\"training\" + 0.005*\"function\" + 0.005*\"one\"'), (5, u'0.008*\"network\" + 0.007*\"model\" + 0.006*\"neural\" + 0.005*\"learning\" + 0.005*\"set\"'), (6, u'0.007*\"model\" + 0.005*\"neural\" + 0.005*\"network\" + 0.005*\"function\" + 0.005*\"figure\"'), (7, u'0.008*\"model\" + 0.006*\"neural\" + 0.005*\"figure\" + 0.005*\"learning\" + 0.004*\"network\"'), (8, u'0.007*\"learning\" + 0.007*\"model\" + 0.006*\"network\" + 0.006*\"function\" + 0.005*\"data\"'), (9, u'0.007*\"input\" + 0.007*\"network\" + 0.005*\"neural\" + 0.005*\"set\" + 0.005*\"time\"'), (10, u'0.007*\"model\" + 0.005*\"learning\" + 0.005*\"network\" + 0.004*\"networks\" + 0.004*\"input\"'), (11, u'0.006*\"learning\" + 0.005*\"neural\" + 0.005*\"figure\" + 0.005*\"function\" + 0.005*\"network\"'), (12, u'0.007*\"model\" + 0.007*\"learning\" + 0.007*\"network\" + 0.006*\"neural\" + 0.005*\"input\"'), (13, u'0.007*\"set\" + 0.007*\"network\" + 0.005*\"neural\" + 0.005*\"function\" + 0.005*\"learning\"'), (14, u'0.008*\"network\" + 0.006*\"neural\" + 0.005*\"networks\" + 0.005*\"one\" + 0.005*\"learning\"'), (15, u'0.008*\"network\" + 0.006*\"learning\" + 0.006*\"function\" + 0.006*\"time\" + 0.006*\"input\"'), (16, u'0.008*\"learning\" + 0.006*\"network\" + 0.005*\"model\" + 0.004*\"figure\" + 0.004*\"training\"'), (17, u'0.008*\"network\" + 0.007*\"neural\" + 0.006*\"input\" + 0.005*\"learning\" + 0.005*\"data\"'), (18, u'0.006*\"network\" + 0.005*\"neural\" + 0.005*\"data\" + 0.005*\"training\" + 0.005*\"set\"'), (19, u'0.007*\"model\" + 0.007*\"network\" + 0.006*\"learning\" + 0.005*\"neural\" + 0.004*\"networks\"'), (20, u'0.006*\"model\" + 0.005*\"learning\" + 0.005*\"data\" + 0.004*\"network\" + 0.004*\"figure\"'), (21, u'0.006*\"neural\" + 0.006*\"network\" + 0.005*\"input\" + 0.005*\"data\" + 0.005*\"set\"'), (22, u'0.007*\"network\" + 0.007*\"model\" + 0.005*\"function\" + 0.005*\"networks\" + 0.005*\"learning\"'), (23, u'0.006*\"learning\" + 0.006*\"networks\" + 0.006*\"model\" + 0.006*\"function\" + 0.006*\"neural\"'), (24, u'0.006*\"learning\" + 0.006*\"network\" + 0.005*\"neural\" + 0.005*\"model\" + 0.005*\"set\"'), (25, u'0.009*\"network\" + 0.006*\"neural\" + 0.006*\"model\" + 0.006*\"learning\" + 0.005*\"networks\"'), (26, u'0.008*\"network\" + 0.008*\"data\" + 0.006*\"figure\" + 0.006*\"input\" + 0.006*\"model\"'), (27, u'0.008*\"network\" + 0.006*\"learning\" + 0.006*\"input\" + 0.005*\"data\" + 0.005*\"function\"'), (28, u'0.010*\"neural\" + 0.006*\"network\" + 0.006*\"model\" + 0.006*\"learning\" + 0.004*\"one\"'), (29, u'0.009*\"learning\" + 0.005*\"one\" + 0.005*\"function\" + 0.005*\"model\" + 0.005*\"using\"'), (30, u'0.006*\"network\" + 0.006*\"figure\" + 0.005*\"model\" + 0.005*\"data\" + 0.004*\"neural\"'), (31, u'0.008*\"learning\" + 0.007*\"network\" + 0.005*\"neural\" + 0.005*\"one\" + 0.005*\"model\"'), (32, u'0.008*\"network\" + 0.007*\"learning\" + 0.007*\"data\" + 0.006*\"networks\" + 0.005*\"neural\"'), (33, u'0.008*\"model\" + 0.007*\"neural\" + 0.005*\"function\" + 0.005*\"learning\" + 0.005*\"input\"'), (34, u'0.010*\"learning\" + 0.006*\"networks\" + 0.006*\"model\" + 0.005*\"neural\" + 0.005*\"figure\"'), (35, u'0.010*\"training\" + 0.009*\"network\" + 0.008*\"learning\" + 0.005*\"model\" + 0.005*\"using\"'), (36, u'0.007*\"learning\" + 0.006*\"network\" + 0.006*\"model\" + 0.005*\"one\" + 0.005*\"input\"'), (37, u'0.006*\"network\" + 0.005*\"neural\" + 0.005*\"learning\" + 0.004*\"networks\" + 0.004*\"data\"'), (38, u'0.006*\"model\" + 0.005*\"network\" + 0.005*\"learning\" + 0.004*\"data\" + 0.004*\"two\"'), (39, u'0.007*\"model\" + 0.007*\"learning\" + 0.006*\"function\" + 0.005*\"data\" + 0.005*\"neural\"'), (40, u'0.008*\"learning\" + 0.006*\"time\" + 0.006*\"training\" + 0.006*\"network\" + 0.005*\"one\"'), (41, u'0.008*\"network\" + 0.007*\"data\" + 0.007*\"neural\" + 0.006*\"model\" + 0.006*\"input\"'), (42, u'0.008*\"learning\" + 0.006*\"model\" + 0.006*\"figure\" + 0.005*\"network\" + 0.005*\"system\"'), (43, u'0.008*\"network\" + 0.006*\"neural\" + 0.006*\"input\" + 0.005*\"networks\" + 0.005*\"figure\"'), (44, u'0.012*\"learning\" + 0.006*\"network\" + 0.006*\"neural\" + 0.005*\"data\" + 0.004*\"algorithm\"'), (45, u'0.007*\"model\" + 0.006*\"network\" + 0.005*\"learning\" + 0.005*\"one\" + 0.005*\"neural\"'), (46, u'0.007*\"input\" + 0.006*\"network\" + 0.005*\"set\" + 0.004*\"function\" + 0.004*\"training\"'), (47, u'0.010*\"network\" + 0.006*\"model\" + 0.005*\"neural\" + 0.005*\"networks\" + 0.005*\"learning\"'), (48, u'0.007*\"network\" + 0.007*\"learning\" + 0.005*\"input\" + 0.005*\"neural\" + 0.005*\"networks\"'), (49, u'0.007*\"network\" + 0.007*\"function\" + 0.006*\"learning\" + 0.006*\"data\" + 0.005*\"set\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 20  and a=  auto\n",
      "[(0, u'0.006*\"network\" + 0.006*\"learning\" + 0.006*\"using\" + 0.005*\"neural\" + 0.005*\"time\"'), (1, u'0.006*\"model\" + 0.005*\"learning\" + 0.005*\"network\" + 0.005*\"neural\" + 0.005*\"time\"'), (2, u'0.007*\"learning\" + 0.007*\"network\" + 0.006*\"model\" + 0.006*\"set\" + 0.005*\"neural\"'), (3, u'0.007*\"network\" + 0.006*\"one\" + 0.006*\"networks\" + 0.005*\"set\" + 0.005*\"neural\"'), (4, u'0.008*\"learning\" + 0.007*\"model\" + 0.006*\"network\" + 0.005*\"neural\" + 0.005*\"input\"'), (5, u'0.007*\"network\" + 0.006*\"data\" + 0.005*\"function\" + 0.005*\"neural\" + 0.005*\"model\"'), (6, u'0.006*\"data\" + 0.005*\"figure\" + 0.005*\"neural\" + 0.005*\"network\" + 0.005*\"input\"'), (7, u'0.007*\"network\" + 0.006*\"model\" + 0.006*\"function\" + 0.006*\"neural\" + 0.005*\"data\"'), (8, u'0.006*\"input\" + 0.005*\"network\" + 0.005*\"model\" + 0.005*\"neural\" + 0.005*\"two\"'), (9, u'0.007*\"model\" + 0.007*\"neural\" + 0.006*\"learning\" + 0.005*\"network\" + 0.005*\"training\"'), (10, u'0.010*\"network\" + 0.008*\"learning\" + 0.006*\"model\" + 0.005*\"input\" + 0.005*\"function\"'), (11, u'0.009*\"learning\" + 0.005*\"neural\" + 0.005*\"set\" + 0.005*\"network\" + 0.005*\"data\"'), (12, u'0.007*\"model\" + 0.006*\"network\" + 0.006*\"data\" + 0.005*\"learning\" + 0.005*\"error\"'), (13, u'0.009*\"network\" + 0.008*\"learning\" + 0.005*\"training\" + 0.005*\"neural\" + 0.005*\"networks\"'), (14, u'0.006*\"network\" + 0.006*\"learning\" + 0.005*\"input\" + 0.005*\"neural\" + 0.005*\"networks\"'), (15, u'0.009*\"learning\" + 0.006*\"network\" + 0.005*\"training\" + 0.004*\"figure\" + 0.004*\"neural\"'), (16, u'0.008*\"network\" + 0.007*\"model\" + 0.006*\"neural\" + 0.006*\"input\" + 0.005*\"figure\"'), (17, u'0.008*\"figure\" + 0.008*\"network\" + 0.006*\"learning\" + 0.005*\"input\" + 0.005*\"model\"'), (18, u'0.006*\"model\" + 0.006*\"one\" + 0.005*\"learning\" + 0.005*\"input\" + 0.005*\"network\"'), (19, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"model\" + 0.004*\"figure\" + 0.004*\"using\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 20  and a=  asymmetric\n",
      "[(0, u'0.008*\"network\" + 0.005*\"figure\" + 0.005*\"one\" + 0.005*\"set\" + 0.004*\"neural\"'), (1, u'0.006*\"learning\" + 0.005*\"neural\" + 0.005*\"data\" + 0.005*\"time\" + 0.005*\"function\"'), (2, u'0.006*\"model\" + 0.006*\"input\" + 0.005*\"function\" + 0.005*\"learning\" + 0.005*\"figure\"'), (3, u'0.007*\"learning\" + 0.007*\"network\" + 0.006*\"training\" + 0.006*\"neural\" + 0.005*\"function\"'), (4, u'0.009*\"model\" + 0.007*\"network\" + 0.005*\"one\" + 0.005*\"learning\" + 0.005*\"data\"'), (5, u'0.007*\"network\" + 0.006*\"model\" + 0.006*\"one\" + 0.005*\"learning\" + 0.005*\"data\"'), (6, u'0.006*\"learning\" + 0.006*\"network\" + 0.005*\"networks\" + 0.005*\"using\" + 0.005*\"set\"'), (7, u'0.008*\"network\" + 0.008*\"learning\" + 0.007*\"input\" + 0.006*\"neural\" + 0.005*\"model\"'), (8, u'0.007*\"learning\" + 0.007*\"network\" + 0.005*\"figure\" + 0.005*\"data\" + 0.005*\"neural\"'), (9, u'0.009*\"model\" + 0.006*\"network\" + 0.006*\"learning\" + 0.005*\"neural\" + 0.005*\"networks\"'), (10, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"data\" + 0.005*\"model\" + 0.005*\"neural\"'), (11, u'0.008*\"neural\" + 0.008*\"network\" + 0.006*\"learning\" + 0.005*\"networks\" + 0.005*\"two\"'), (12, u'0.008*\"learning\" + 0.006*\"data\" + 0.006*\"model\" + 0.006*\"training\" + 0.005*\"neural\"'), (13, u'0.006*\"model\" + 0.006*\"network\" + 0.005*\"learning\" + 0.005*\"algorithm\" + 0.005*\"neural\"'), (14, u'0.009*\"network\" + 0.006*\"neural\" + 0.006*\"one\" + 0.005*\"learning\" + 0.005*\"input\"'), (15, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"function\" + 0.005*\"neural\" + 0.005*\"input\"'), (16, u'0.008*\"model\" + 0.007*\"learning\" + 0.006*\"network\" + 0.005*\"function\" + 0.005*\"neural\"'), (17, u'0.008*\"network\" + 0.006*\"neural\" + 0.006*\"function\" + 0.006*\"data\" + 0.005*\"model\"'), (18, u'0.007*\"network\" + 0.006*\"learning\" + 0.006*\"model\" + 0.006*\"figure\" + 0.005*\"input\"'), (19, u'0.008*\"network\" + 0.005*\"figure\" + 0.005*\"one\" + 0.005*\"time\" + 0.005*\"input\"')]\n",
      "\n",
      "\n",
      "For numberOfTopics= 20  and a=  symmetric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.008*\"network\" + 0.008*\"model\" + 0.007*\"learning\" + 0.005*\"function\" + 0.005*\"error\"'), (1, u'0.006*\"network\" + 0.006*\"model\" + 0.005*\"learning\" + 0.005*\"neural\" + 0.004*\"figure\"'), (2, u'0.007*\"network\" + 0.006*\"learning\" + 0.005*\"function\" + 0.005*\"neural\" + 0.005*\"figure\"'), (3, u'0.008*\"network\" + 0.007*\"learning\" + 0.005*\"input\" + 0.005*\"function\" + 0.005*\"model\"'), (4, u'0.006*\"data\" + 0.006*\"neural\" + 0.005*\"network\" + 0.005*\"learning\" + 0.005*\"input\"'), (5, u'0.007*\"model\" + 0.006*\"network\" + 0.006*\"learning\" + 0.005*\"data\" + 0.005*\"one\"'), (6, u'0.006*\"neural\" + 0.006*\"learning\" + 0.006*\"network\" + 0.005*\"figure\" + 0.005*\"input\"'), (7, u'0.006*\"network\" + 0.006*\"learning\" + 0.006*\"neural\" + 0.005*\"set\" + 0.005*\"training\"'), (8, u'0.007*\"network\" + 0.005*\"neural\" + 0.005*\"data\" + 0.005*\"set\" + 0.005*\"training\"'), (9, u'0.008*\"network\" + 0.007*\"neural\" + 0.007*\"input\" + 0.006*\"networks\" + 0.005*\"model\"'), (10, u'0.007*\"learning\" + 0.007*\"one\" + 0.006*\"model\" + 0.005*\"figure\" + 0.005*\"input\"'), (11, u'0.006*\"neural\" + 0.005*\"network\" + 0.005*\"model\" + 0.004*\"learning\" + 0.004*\"algorithm\"'), (12, u'0.009*\"learning\" + 0.007*\"network\" + 0.005*\"model\" + 0.005*\"set\" + 0.005*\"training\"'), (13, u'0.007*\"network\" + 0.007*\"neural\" + 0.006*\"model\" + 0.006*\"data\" + 0.005*\"figure\"'), (14, u'0.008*\"network\" + 0.006*\"model\" + 0.006*\"figure\" + 0.005*\"learning\" + 0.005*\"data\"'), (15, u'0.008*\"learning\" + 0.007*\"network\" + 0.006*\"model\" + 0.006*\"one\" + 0.005*\"neural\"'), (16, u'0.006*\"learning\" + 0.005*\"model\" + 0.004*\"network\" + 0.004*\"networks\" + 0.004*\"one\"'), (17, u'0.007*\"learning\" + 0.007*\"model\" + 0.006*\"network\" + 0.006*\"data\" + 0.005*\"function\"'), (18, u'0.006*\"learning\" + 0.005*\"function\" + 0.005*\"model\" + 0.005*\"networks\" + 0.005*\"error\"'), (19, u'0.006*\"network\" + 0.005*\"learning\" + 0.005*\"model\" + 0.005*\"using\" + 0.005*\"neural\"')]\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "from operator import itemgetter\n",
    "\n",
    "num_topics=[10,50,20]\n",
    "alpha=[\"auto\",\"asymmetric\",\"symmetric\"]\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "for topicNo in num_topics:\n",
    "    for a in alpha:\n",
    "        print \"\\n\\nFor numberOfTopics=\",topicNo,\" and a= \",a\n",
    "        ldamodel = Lda(corpus=doc_term_matrix, num_topics=topicNo, id2word = dictionary,alpha=a)\n",
    "        print ldamodel.print_topics(num_topics=topicNo, num_words=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#5642C2\" size=\"3\">Visualizing Results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitting topic for each Document\n",
      "------------------------------------\n",
      "Document  0 topic:  4\n",
      "Document  1 topic:  12\n",
      "Document  2 topic:  10\n",
      "Document  3 topic:  9\n",
      "Document  4 topic:  17\n",
      ".......\n"
     ]
    }
   ],
   "source": [
    "#printing most representative topic for the 10 fist documents        \n",
    "print \"Best fitting topic for each Document\"\n",
    "print \"------------------------------------\"\n",
    "for idx,doc in enumerate(doc_term_matrix[:5]):\n",
    "    print \"Document \",idx, \"topic: \",\\\n",
    "    max(ldamodel.get_document_topics(doc),key=lambda item:item[1])[0]\n",
    "print \".......\"\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
